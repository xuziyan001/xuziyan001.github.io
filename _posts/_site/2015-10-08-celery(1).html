<p>
作为分布式调度系统，celery真正承载了异步任务消息的分发以及对消息队列的控制。通过对所监视队列的监听，独立的celery worker进程持续处理队列中的新消息，而RabbitMQ相当于任务生产者与实际worker之间的通道，下面简单的做一个celery的demo。
</p>
<h3>Configuration</h3>
<p>
模块的配置最好还是和应用的实体分离，所以这边推荐模块化的配置方式，将所有的相关配置都写在一个配置文件中：<br />

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># celeryconfig.py</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="n">BROKER_URL</span> <span class="o">=</span> <span class="s">&#39;amqp://guest:guest@localhost:5672&#39;</span>
<span class="n">CELERY_RESULT_BACKEND</span> <span class="o">=</span> <span class="s">&#39;amqp://&#39;</span>
<span class="n">CELERY_TIMEZONE</span> <span class="o">=</span> <span class="s">&#39;Asia/Shanghai&#39;</span>
<span class="n">CELERY_ENABLE_UTC</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">CELERT_ROUTES</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">&#39;tasks.add&#39;</span><span class="p">:</span> <span class="s">&#39;low-priority&#39;</span><span class="p">,</span>
                <span class="s">&#39;tasks.mul&#39;</span><span class="p">:</span> <span class="s">&#39;high-priority&#39;</span><span class="p">,</span> 
                <span class="p">}</span></code></pre></div>

celery也就是用一些常量来控制celery的行为，这些常量在程序中都有一个默认值，通过config_from_object()方法，一个celery app的实例就可以从配置文件中获取新的配置值，所有的配置参数在<a href="http://docs.celeryproject.org/en/latest/configuration.html">这里</a>。
</p>
<h3>Application &amp; Tasks</h3>
<p>
Application就是Celery的一个实例，通过配置文件的方式，Application在声明时就不需要提供太多额外参数，大部分情况下只需提供一个app_name即可：<br />

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="s">&#39;lejent&#39;</span><span class="p">)</span></code></pre></div>

Task使用标签化的方法，指定一个Application，或者公用的任务方法：

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="nd">@app.task</span><span class="p">(</span><span class="n">max_retries</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span></code></pre></div>

task标签中也可以定义max_retries, rate_limit等配置参数，重要的是，由于异步任务不能保证请求处理的顺序以及消息处理的次数，所以所有的worker需要通过事务或者状态引擎来保证自身的幂等性。
任务一旦被创建，celery提供三种方式调用tasks:
<ul>
  <li>__call__，不走消息通道，对任务直接同步调用。</li>
  <li>apply_async，标准的异步调用，支持eta，countdown，expires，retry等参数，为异步调用选择通道及相应的策略。</li>
  <li>delay，apply_async的简化接口，不提供执行执行条件，采用默认策略执行异步调用。</li>
</ul>
</p>
<h3>Subtask &amp; Work Flow</h3>
<p>
异步任务可以被分为一系列的子任务，它可以将一个任务的部分参数传递并且等待另一部分参数回调，从而形成任务执行链。celery提供一系列的原语来控制任务的执行流。
<h4>chain</h4>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">res</span> <span class="o">=</span> <span class="n">chain</span><span class="p">(</span><span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="mi">8</span><span class="p">))()</span>
<span class="n">res</span><span class="o">.</span><span class="n">get</span><span class="p">()</span> <span class="c">#2+2+4+8=16</span></code></pre></div>

将前一个任务返回值传递给下一个子任务，以此类推。
<h4>group</h4>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">res</span> <span class="o">=</span> <span class="n">group</span><span class="p">(</span><span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">6</span><span class="p">))()</span>
<span class="n">res</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c">#[0,2,4,6,8,10]</span></code></pre></div>

group内的所有子任务是并发执行的，在get的时候会等待所有任务全部完成之后返回。
<h4>chord</h4>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">res</span> <span class="o">=</span> <span class="n">chord</span><span class="p">((</span><span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="n">xsum</span><span class="o">.</span><span class="n">s</span><span class="p">())()</span>
<span class="n">res</span><span class="o">.</span><span class="n">get</span><span class="p">()</span> <span class="c">#90</span></code></pre></div>

chord将任务串起来，其实原理同下：

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="n">group</span><span class="p">(</span><span class="n">add</span><span class="o">.</span><span class="n">s</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="o">|</span> <span class="n">xsum</span><span class="o">.</span><span class="n">s</span><span class="p">())()</span>
<span class="n">res</span><span class="o">.</span><span class="n">get</span><span class="p">()</span> <span class="c">#90</span></code></pre></div>

<h4>map &amp; startmap</h4>
与group不同，map只传递一个message，函数计算是线性的，和python内置的map类似；starmap用来传递iterable的对象：

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">~</span><span class="n">add</span><span class="o">.</span><span class="n">starmap</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span>
<span class="c"># [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]</span></code></pre></div>

~是对异步任务调用加等待返回的简写，如上调用直接等待任务get后的返回值。
<h4>chunks</h4>
chunks可以将多个任务进行分块，在高负荷情况下平衡并行度和message头开销：

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">add</span><span class="o">.</span><span class="n">chunks</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)),</span> <span class="mi">10</span><span class="p">)</span></code></pre></div>

</p>
<h3>Monitoring</h3>
<p>
Celery在命令行提供了一系列的对worker的监控机制，但最方便的还是通过网页可视化监控比较方面。Flower就是一个实时监控管理的工具，首先安装包：<br />

<div class="highlight"><pre><code class="language-console" data-lang="console"><span class="go">pip install flower</span></code></pre></div>

然后对当前worker启动监控：

<div class="highlight"><pre><code class="language-console" data-lang="console"><span class="go">celery -A proj flower</span></code></pre></div>

flower的默认端口是5555，直接打开浏览器就可以监控当前机器的celery工作状态。
</p>
<h3>Start</h3>
<p>
现在启动我们的celery进程，首先保证rabbitmq已经启动完毕，然后启动celery worker，进程要多多多：<br />

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">celery</span> <span class="n">multi</span> <span class="n">start</span> <span class="mi">2</span> <span class="o">-</span><span class="n">A</span> <span class="n">tasks</span> <span class="o">-</span><span class="n">l</span> <span class="n">info</span> <span class="o">-</span><span class="n">c47</span> <span class="o">--</span><span class="n">pidfile</span><span class="o">=./%</span><span class="n">n</span><span class="o">.</span><span class="n">pid</span></code></pre></div>

启动两个worker（multi start 2），每个worker 48个进程（c47）
</p>

